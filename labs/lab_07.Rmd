---
title: "lab_07"
author: "derek willis"
date: "2023-03-28"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidycensus)
library(dplyr)
```

## You will need

-   A Census API key

## Load libraries and establish settings

You'll need to load two packages for this: the tidyverse and tidycensus.

**Task** load these two packages

```{r}
# Turn off scientific notation
options(scipen=999)

# Load the tidyverse.
```

## Setup Census API

You'll need your Census API Key:

**Task** set your API Key if you haven't already. You won't need to install or overwrite it.

```{r echo=FALSE}
census_api_key("342dc03e628e6078f3385d0702a9593746840878", install=TRUE, overwrite = TRUE)
```

## Load and view ACS variables

You'll also need to load the list of American Community Survey variables from the 2021 5-year estimates so you can identify the codes you need:

**Task** load the variables from the 2021 5-year ACS (which is called "acs5") and save them to a dataframe

```{r}
acs21 <- load_variables(2021, "acs5", cache = TRUE)
view(acs21)
```

## Answer questions

**Q1** What is the Maryland jurisdiction with the lowest median age, according to the ACS 2021 5-year estimates? You will need to find the variable for median age first. 
**A1** Baltimore City

```{r}
medium_age_variable <- get_acs(geography = "county",variables = c(medianage = "B01002_001E"), state = "MD")

medium_age_variable_ordered <- medium_age_variable %>%
  arrange(estimate)
```

**Q2** Which Maryland counties have a median age of at least 50? You can use the dataframe you just made to answer this, but you must write code to display only those counties with a median age of at least 50. 
**A2** Talbot and Worchester County

```{r}
medium_50_plus <- medium_age_variable %>%
    filter(estimate >= 50)
```

**Q3** We're interested in knowing more about Montgomery County zip codes where overdose calls are coming from and the demographic characteristics they possess. In particular, we want to calculate a rate of calls per 1,000 population. To do this, you'll need to:

1. Load the Montgomery County 911 overdose calls data.
2. Create a new dataframe with the total number of calls for each zip code.
3. Find the ACS variable pertaining to the total 18 and up population (there are several choices here; you want the simplest one).
4. Get from the ACS data from all Maryland zip codes using that variable.
5. Join the ACS data to the Montgomery County zip code totals dataframe and rename the estimate column to a meaningful name you've given the ACS variable.
6. Add a column to the joined dataframe that calculates a rate of calls per 1,000 population.

Which zip code has the highest rate of calls? Which has the lowest?

**A3** Lowest: 20707 Highest: 20877

```{r}
montgomery <- read_csv("data/montgomery_2022_overdoses.csv")

mont_calls_per_zip <- montgomery %>%
  mutate(zip = as.character(zip)) %>%
  group_by(zip) %>%
  summarise(calls = n())

acs_md <- get_acs(geography = "zcta", variables = "B01001_001E", state = "MD", year = 2019)

mont_calls_per_zip_with_acs <- mont_calls_per_zip %>% left_join(acs_md, by=c('zip'='GEOID')) %>%
  rename("pop_over_18" = estimate) %>%
  mutate(callrate_per_1000 = (calls / pop_over_18) * 1000) %>%
  arrange(callrate_per_1000)
  
```

**Q4** Using [CensusReporter.org](https://censusreporter.org/), examine the zip codes with the highest and lowest rates and compare and contrast their demographic profiles. Is there a story here?

**A4** After examining the demographics of the zip codes in the top fice and bottom five of call rates, I don't see a lot of patterns. It seems that demographics are about the same for each, with most of the conuties on both sides being majority white. Both sides about even gender distributions and average age seemed fairly random. The only pattern I see is it seems zips with low call rates tended to have higher average household incomes then zips with high call rates, which seems to tell that places with higher average household incomes can translate into lower call rates. However, with the margin of error between the call data and the census data, I'm not sure if there is enough of a difference to make a story out of it. 

**Q5** Go back to your joined dataframe from Q3 and add two more columns representing the minimum and maximum populations based on the estimate and margin of error, then calculate per capita rates for each. Do you get the same two zip codes for the highest and lowest as you did before? Does that give you more or less confidence in your answers to Q3?

**A5** For the maximum population rate, it is 2 different zip codes then before when looking at the highest call rates as well as the lowest call rate.  For the minimum population rate, the sme is true. This defintely makes me less cofident in our findings from Q3 as we can see the argin of error can result in us getting completley different answers in every way possible. 

```{r}
mont_calls_per_zip_with_acs %>%
  mutate(max_pop = (pop_over_18 + moe)) %>%
  mutate(min_pop = (pop_over_18 - moe)) %>%
  mutate(max_pop_rate = (max_pop / pop_over_18) * 1000) %>%
  mutate(min_pop_rate = (min_pop / pop_over_18) * 1000) %>%
  arrange(desc(min_pop_rate))
```

